\chapter{Compute Layer}\label{compute-ch}

The compute layer is responsible for two important sections of Pinky's
functionality. First, this layer handles interaction between the storage layer
by using the \c{StorageBackend} abstraction to read and write datasets.
Secondly, it interacts with the visualization layer by performing calculations a
client's request and transferring data back for rendering. In addition, this
layer also contains implementations of optimized algorithms for processing EEG
data to calculate the spectrogram.

\section{Design}

Since this layer of the system supports a variety of features, we separate the
design points for each. As with other layers, minimizing runtime was one of the
key design goals. Another design point we focused on was enabling developers to
easily modify and add new processing algorithms.

\subsection{Websocket Server}

The websocket server is responsible for transferring array based data to the
client for rendering. The server must be able to quickly serialize data from
the storage layer, namely multidimensional arrays of floating point values. The
server must be able to run concurrently in order to handle multiple client
requests, processing the requests in parallel to reduce latency.

\subsection{Webapp Server}

The webapp server is responsible for serving web resources such as JavaScript,
HTML, and CSS to the client. The scripts sent to the client are responsible for
communicating with the websocket server, retrieving data for display. This
server is separate from the websocket server to simplify the implementation
since the webapp server is not subject to the same performance requirements
when transferring datasets over the network. The separation of these two
servers allows for future modules to be easily added to the webapp framework
using existing frameworks (see Section~\ref{compute-ch:implementation-webapp})
such as authentication.

\subsection{File Ingestion Daemon}

The file ingestion daemon is responsible for collecting new files that are
added to the system and converting them for use. This makes use of conversions
between the EDF format and the required format for the \c{StorageBackend} that
is in use. Input files are initially received in the EDF format and must
subsequently be converted without affecting other clients who are using the
system.

\subsection{Spectrogram Calculation}\label{compute-ch:design-spectrogram}

The EEG spectrogram transforms the raw voltage readings from a patient
screening, converting them into frequency space. Formally, if $x$ is a signal
of length $N$, we consecutively take windows of $x$ of length $m$ ($m \ll N$),
creating the matrix $X \in \mathbb{R}^{m \times (N - m + 1)}$ where consecutive
segments of $x$ are consecutive columns in $X$. Thus, the first column of $X$
is $[x[0], x[1], \ldots, x[m-1]]^T$, followed by $[x[1], x[2], \ldots,
x[m]]^T$, and so forth. \\

Following this, the spectrogram of $x$ with a window size $m$ is defined as the
matrix $\hat{X}$, where the columns of $\hat{X}$ are the Discrete Fourier
Transform (DFT) of $X$, or $\hat{X} = \bar{F}X$. \\

The spectrogram calculation depends on the windowing function, the window size,
the overlap between windows and the number of points chosen when performing the
DFT. We make these parameters configurable to suite an analysts' needs;
supporting different kinds of analysis and also testing for the optimal
configuration. The default configuration uses the Hamming windowing function, a
window size defined as \c{(nsamples - nfft) / (fs * 4)}, and overlap equal to
\c{fs}. \\

The Hamming window is defined as $w(n) = 0.54 - 0.46*\cos(\frac{2 \pi n}{N
  -1})$ for a discrete signal $w[n]$, $0 \leq n \leq N -1$. \c{nsamples} is the
number of samples in the input signal, \c{nfft = next\_power\_of\_2(fs)},
and \c{fs} is the sampling frequency of the input signal.

\section{Implementation}

We implement the compute layer almost entirely in C++ except for the file
ingestion daemon and webapp server, which are written in Python. The Python
implementations comprise a much smaller part of the compute layer codebase
since there are a number of libraries available in the community. Although
there is a development and infrastructure overhead for using multiple languages
within the system, Python seemed the appropriate choice in this circumstance
due to the reduced developer time and availability of mature libraries. C++ was
chosen for the other parts of the module since the performance gains with a
compiled language were necessary. C++ was chosen over pure C because of the
available libraries for linear algebra processing \cite{arma} and network
communication \cite{websocket-server}.

\subsection{Websocket Server}\label{compute-ch:implementation-ws-server}

The websocket server primarily depends on the open source library
\c{Simple-WebSocket-Server} \cite{websocket-server}. This library implements
the websocket protocol and provides a simple interface for transferring data
across the network. The library was not without it's own bugs, over the course
of developing Pinky we reported and helped debug concurrency issues with the
generous help of the maintainer.  These bug fixes also resulted in large
performance gains from the original library implementation because of reduced
network latency.  \\

When loading the Pinky frontend into their browser, the client sends a request
to the websocket server to open a connection. When the client wishes to browse
a patient's data, a request is sent specifying the patient's \c{mrn}, a
\c{start\_time} and \c{end\_time} given in hours. \\

The websocket server then requests a spectrogram with the given values either
computing the spectrogram on the fly or using a precomputed spectrogram
calculation. The websocket server with potentially downsample the response to
meet client latency requirements, the details of this are described in
Chapter~\ref{visgoth-ch}. \\

To send data back to the client, a JSON encoded header is created, notifying
the client with the calculation results. The header contains a small amount of
metadata such as the sampling rate, \c{fs}, calculated \c{start\_time} and
\c{end\_time} (we validate these values to the bounds of the dataset),
spectrogram matrix dimensions and the \c{channel} for the calculation.  The
messaging protocal transfers the binary array data encoding a header length in
a \c{uint32\_t} followed by the serialized header information and the matrix
data. All messages are byte aligned to 8 bytes, so we sometimes add a small
amount of padding for performance reasons. \\

The websocket spawns $n_{processors} - 1$ threads to serve requests with. For
development and testing we have use the CSAIL OpenStack framework to create
multicore virtual machines of different sizes for testing.

\subsection{Webapp Server}\label{compute-ch:implementation-webapp}

We implement the webapp server using the Python mircoframework Flask
\cite{flask}. The Flask framework allows simple serving of HTML webpages with
support of the Jinja2 \cite{jinja2} templating system. This is vastly easier to
develop on than maintain than a comparable C++ implementation, and since
performance is not an issue, Python it is a viable option. \\

The server provides web resources for the client as well as pages with
information about the project.

\subsection{File Ingestion Daemon}

The file ingestion daemon monitors the server's filesystem for changes in order
to ingest new data files. Taking advantage of the Python Watchdog
\cite{watchdog} library, the script is able to receive events for changes to
the filesystem for a given folder. Upon receiving a notification, the script
will convert the file to the necessary format and also precompute the
spectrogram. To process the file, the script calls the command line programs
\c{edf\_converter <mrn>} (Section~\ref{storage-ch:implementation-cmd}) and
\c{precompute\_spectrogram <mrn>}
(Section~\ref{compute-ch:implementation-cmd}). \\

This functionality allows an administrator to dump EDF files onto the
filesystem of the server and allow an analyst to automatically query them after
conversion.

\subsection{Spectrogram Calculation}\label{compute-ch:implementation-spectrogram}

The spectrogram calculation involves reading portions of the raw EEG data,
taking the FFT of the data with a sliding window in time and storing the
results in a matrix for visualization. The spectrogram computation can vary
based on a number of parameters, and to simplify the implementation, we store
all relevant spectrogram parameters in an object, \c{SpecParams}. When a client
requests a spectrogram for a given region of the brain, we create this object,
building the parameters from the input \c{mrn}, \c{start\_time} and
\c{end\_time}. \\

The \c{SpecParams} object contains the following parameters, the comments next
to each parameter describe it's use.

\begin{lstlisting}
    string mrn; // patient medical record number
    StorageBackend* backend; // array storage backend
    float start_time; // start time of the spectrogram
    float end_time; // end time of spectrogram
    int start_offset; // start offset of raw data
    int end_offset; // end offset of raw data
    int spec_start_offset; // start offset of spectrogram data
    int spec_end_offset; // start offset of spectrogram data
    int fs; // sample rate
    int nfft; // number of samples for fft
    int nstep; // number of steps
    int shift; // shift size for windows
    int nsamples; // number of samples in the spectrogram
    int nblocks; // number of blocks
    int nfreqs; // number of frequencies
\end{lstlisting}

Using the \c{SpecParams} object, we can calculate the spectrogram for the EEG
data. Section~\ref{compute-ch:design-spectrogram} details the description of
the algorithm. The algorithm's pseudocode is as follows:

\begin{lstlisting}
void eeg_spectrogram(SpecParams* spec_params, int ch, fmat& spec_mat)
{
  // Get the column which contains the first channel for the region.
  ch_idx1 = DIFFERENCE_PAIRS[ch].ch_idx[0];
  frowvec vec1, vec2; // initialize read vectors
  read_array(mrn, ch_idx1, start_offset, end_offset, vec1);

  for (int i = 1; i < NUM_DIFFS; i++)
  {
    // Get the column which contains the next channel for the region.
    ch_idx2 = DIFFERENCE_PAIRS[ch].ch_idx[i];
    read_array(mrn, ch_idx2, start_offset, end_offset, vec2);
    // take the difference between the channel pair
    frowvec diff = vec2 - vec1;

    // fill in the spec matrix with FFT values
    FFT(spec_params, diff, spec_mat);
    swap(vec1, vec2);
  }
  spec_mat /=  (NUM_DIFFS - 1); // average diff spectrograms
  spec_mat = spec_mat.t(); // transpose the output
}
\end{lstlisting}

The definition of the constants \c{DIFFERENCE\_PAIRS} and \c{NUM\_DIFFS} are
omitted from the pseudocode for simplicity. The \c{DIFFERENCE\_PAIRS} simply
defines which channels to take differences to form a region (see
Section~\ref{intro-ch:eeg-overview}) and \c{NUM\_DIFFS=4} since we
compute the spectrogram across four different regions of the brain. \\

We implement the FFT algorithm with the FFTW library \cite{fftw} for optimal
performance. We make use of the Armadillio C++ linear algebra library
\cite{arma} for simplifying vector and matrix calculations.

\subsection{Command Line Programs}\label{compute-ch:implementation-cmd}

The compute module offers two command line scripts, \c{test} and
\c{precompute\_spectrogram <mrn>}. The \c{test} script tests the functionality
to an algorithm or \c{StorageBackend}. The \c{precompute\_spectrogram} program
will take a \c{mrn} as input and calculate and store the spectrogram for the
given \c{mrn}.

\subsection{Optimizations}

The implementation of the \c{eeg\_spectrogram} algorithm design aims to
minimize memory consumption. For this reason we reuse the \c{vec1}, \c{vec2},
and \c{spec\_mat} buffers during the calculation. We considered computing each
of the differences for a region in parallel, however computing each region in
parallel (parallelized at the websocket server) was performant enough. Previous
iterations involved serializing the output of the Armadillio matrix (\c{fmat}),
however we found that instead we could directly access a pointer of the raw
buffer memory. This optimization help significantly since it eliminated a
memory allocation and data copying before sending over the network. \\

Another minor optimization is the use of the \c{static inline} keyword. We use
this for helper functions to reduce function call overhead. In addition, we
always pass Aramdillo objects by reference and not value, avoiding a copy on
function calls.

